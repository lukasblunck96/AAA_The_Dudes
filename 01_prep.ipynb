{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, MultiPolygon\n",
    "import vaex\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_trips_all = vaex.open('./data/trips.hdf5')\n",
    "\n",
    "### Replace spaces and uppercases in column names\n",
    "column_names = df_taxi_trips_all.column_names\n",
    "column_names_refactored = [ln.replace(' ', '_').lower() for ln in column_names]\n",
    "\n",
    "for i, column in enumerate(column_names):\n",
    "    df_taxi_trips_all.rename(column, column_names_refactored[i])\n",
    "\n",
    "# correct typo\n",
    "df_taxi_trips_all.rename(\"dropoff_centroid__location\",\"dropoff_centroid_location\")\n",
    "\n",
    "# cast timestamp columns to datetime\n",
    "date_format = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "def column_to_datetime(datetime_str):\n",
    "    return np.datetime64(datetime.strptime(datetime_str, date_format))\n",
    "\n",
    "df_taxi_trips_all['trip_start_timestamp'] = df_taxi_trips_all['trip_start_timestamp'].apply(column_to_datetime)\n",
    "df_taxi_trips_all['trip_end_timestamp'] = df_taxi_trips_all['trip_end_timestamp'].apply(column_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open external data: census tracts\n",
    "df_census_tracts = vaex.open('./data/chicago_census_tracts.csv')\n",
    "df_census_tracts.rename(\"the_geom\", \"geometry\")\n",
    "\n",
    "# community areas\n",
    "df_community_areas = vaex.open('./data/community_areas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of trips: 24,988,003\n"
     ]
    }
   ],
   "source": [
    "total_trips = len(df_taxi_trips_all)\n",
    "print(f\"Total amount of trips: {total_trips:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips with trip_miles = 0: 3,003,697\n",
      "Number of trips without trip miles and same location: 1,387,241\n"
     ]
    }
   ],
   "source": [
    "# Number of trips with trip_miles = 0\n",
    "zero_trip_miles = len(df_taxi_trips_all[df_taxi_trips_all[\"trip_miles\"] == 0])\n",
    "print(f\"Number of trips with trip_miles = 0: {zero_trip_miles:,}\")\n",
    "\n",
    "# Number of trips with trip_miles = 0 and no difference in pickup and dropoff location\n",
    "zero_trip_miles_same_loc = len(df_taxi_trips_all[(df_taxi_trips_all[\"trip_miles\"] == 0) & (df_taxi_trips_all[\"pickup_centroid_location\"] == df_taxi_trips_all[\"dropoff_centroid_location\"])])\n",
    "print(f\"Number of trips without trip miles and same location: {zero_trip_miles_same_loc:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Trips with Zero Trip Miles and Same Pickup/Dropoff Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trips with Non-Zero Trip Miles and Different Pickup/Dropoff Locations: 23,600,762\n"
     ]
    }
   ],
   "source": [
    "# drop rows without trip miles and same location\n",
    "df_non_zero_trip_miles = df_taxi_trips_all[(df_taxi_trips_all[\"trip_miles\"] != 0) | (df_taxi_trips_all[\"pickup_centroid_location\"] != df_taxi_trips_all[\"dropoff_centroid_location\"])]\n",
    "print(f\"Total Trips with Non-Zero Trip Miles and Different Pickup/Dropoff Locations: {len(df_non_zero_trip_miles):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Missing Census Tract IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing pickup_census_tract IDs: 30.76%\n",
      "Percentage of missing dropoff_census_tract IDs: 31.13%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing pickup_census_tract IDs\n",
    "percentage_missing_pickup_census_tract = (len(df_non_zero_trip_miles[df_non_zero_trip_miles[\"pickup_census_tract\"].isnan()]) / len(df_non_zero_trip_miles)) * 100\n",
    "percentage_missing_dropoff_census_tract = (len(df_non_zero_trip_miles[df_non_zero_trip_miles[\"dropoff_census_tract\"].isnan()]) / len(df_non_zero_trip_miles)) * 100\n",
    "\n",
    "# Round the percentage to two decimal places\n",
    "percentage_rounded_pickup = round(percentage_missing_pickup_census_tract, 2)\n",
    "percentage_rounded_dropoff = round(percentage_missing_dropoff_census_tract, 2)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Percentage of missing pickup_census_tract IDs: {percentage_rounded_pickup}%\")\n",
    "print(f\"Percentage of missing dropoff_census_tract IDs: {percentage_rounded_dropoff}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trips without Rows with NA Values in pickup/dropoff_centroid_location AND pickup/dropoff_census_tract: 21,170,643\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows where both \"X_census_tract\" and \"X_centroid_location\" are NA\n",
    "# We keep rows WITH \"X_centroid_location\" and WITHOUT \"pickup_census_tract\" to craft census tracts\n",
    "df_cleaned_census_and_location = df_non_zero_trip_miles.dropna(column_names=[\"pickup_census_tract\", \"pickup_centroid_location\"], how=\"all\")\n",
    "df_cleaned_census_and_location = df_cleaned_census_and_location.dropna(column_names=[\"dropoff_census_tract\", \"dropoff_centroid_location\"], how=\"all\")\n",
    "print(f\"Total Trips without Rows with NA Values in pickup/dropoff_centroid_location AND pickup/dropoff_census_tract: {len(df_cleaned_census_and_location):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows where pickup/dropoff_census_tract is NA: 5,000,517\n"
     ]
    }
   ],
   "source": [
    "df_no_census_tract_both = df_cleaned_census_and_location[df_cleaned_census_and_location[\"pickup_census_tract\"].isna() | df_cleaned_census_and_location[\"dropoff_census_tract\"].isna()]\n",
    "print(f\"Number of Rows where pickup/dropoff_census_tract is NA: {len(df_no_census_tract_both):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have one dataframe containing null values for both pickup_census_tract and dropoff_census_tract\n",
    "# df_no_census_tract_both = df_no_census_tract_both.to_pandas_df()\n",
    "\n",
    "# # Convert the pickup_centroid_location in the dataframe to Point geometries\n",
    "# df_no_census_tract_both['pickup_centroid_location'] = df_no_census_tract_both.apply(\n",
    "#     lambda row: Point(row['pickup_centroid_longitude'], row['pickup_centroid_latitude']), axis=1\n",
    "# )\n",
    "\n",
    "# # Prepare a function to find the census tract for a given point\n",
    "# def find_census_tract(point, census_tract_df):\n",
    "#     for index, row in census_tract_df.iterrows():\n",
    "#         if point.within(row['geometry']):\n",
    "#             return row['GEOID10']\n",
    "#     return None\n",
    "\n",
    "# # Create dictionaries to store the census tract IDs for pickup and dropoff points\n",
    "# pickup_census_tract_ids = {}\n",
    "# dropoff_census_tract_ids = {}\n",
    "\n",
    "# # Iterate through each row of the dataframe and find the corresponding census tract IDs for both pickup and dropoff\n",
    "# for index, row in df_no_census_tract_both.iterrows():\n",
    "#     pickup_location = row['pickup_centroid_location']\n",
    "#     dropoff_location = row['pickup_centroid_location']\n",
    "\n",
    "#     if pickup_location not in pickup_census_tract_ids:\n",
    "#         pickup_census_tract_ids[pickup_location] = find_census_tract(pickup_location, df_census_tracts)\n",
    "\n",
    "#     if dropoff_location not in dropoff_census_tract_ids:\n",
    "#         dropoff_census_tract_ids[dropoff_location] = find_census_tract(dropoff_location, df_census_tracts)\n",
    "\n",
    "# # Update the \"pickup_census_tract\" column\n",
    "# df_no_census_tract_both['pickup_census_tract'] = df_no_census_tract_both['pickup_centroid_location'].map(pickup_census_tract_ids)\n",
    "\n",
    "# # Update the \"dropoff_census_tract\" column\n",
    "# df_no_census_tract_both['dropoff_census_tract'] = df_no_census_tract_both['pickup_centroid_location'].map(dropoff_census_tract_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_census_not_nan = df_cleaned_census_and_location.dropna(column_names=[\"pickup_census_tract\", \"dropoff_census_tract\"])\n",
    "# df_census_not_nan = vaex.from_pandas(df_census_not_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_inserted_census_tracts = df_census_not_nan.concat(df_no_census_tract_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNT NA VALUES - NOT MANDATORY ###\n",
    "# check which values contain NA and NaN values\n",
    "# column_names = df_cleaned_census_and_location.get_column_names()\n",
    "# column_names.remove('trip_start_timestamp')\n",
    "# column_names.remove('trip_end_timestamp')\n",
    "\n",
    "# for column in column_names:\n",
    "#     df_na = df_cleaned_census_and_location[df_cleaned_census_and_location[column].isna()]\n",
    "#     print(f\"Column '{column}' contains NA values with a number of \" + str(len(df_na)) + \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSISTENCY CHECK - NOT MANDATORY ###\n",
    "# # check if trip ids are unique\n",
    "# print(\"Trip IDs are unique?: \" + str(len(df_cleaned_census_and_location) == len(df_cleaned_census_and_location['trip_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the pickup community area IDs in the taxi trip data match the community area dataset?  True\n",
      "Do the dropoff community area IDs in the taxi trip data match the community area dataset?  True\n"
     ]
    }
   ],
   "source": [
    "# check for consistency in community areas\n",
    "community_areas = df_community_areas.AREA_NUMBE.values.unique()\n",
    "community_areas_int = set([area.as_py() for area in community_areas])\n",
    "\n",
    "community_areas_pickup = df_cleaned_census_and_location.pickup_community_area.unique(dropnan=True)\n",
    "community_areas_pickup_int = set([int(area) for area in community_areas_pickup])\n",
    "\n",
    "community_areas_dropoff = df_cleaned_census_and_location.pickup_community_area.unique(dropnan=True)\n",
    "community_areas_dropoff_int = set([int(area) for area in community_areas_dropoff])\n",
    "\n",
    "print(\"Do the pickup community area IDs in the taxi trip data match the community area dataset? \",community_areas_pickup_int.issubset(community_areas_int))\n",
    "print(\"Do the dropoff community area IDs in the taxi trip data match the community area dataset? \",community_areas_dropoff_int.issubset(community_areas_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the pickup census tract IDs in the taxi trip data match the census tract dataset?  False\n",
      "Do the dropoff census tract IDs in the taxi trip data match the census tract dataset?  False\n"
     ]
    }
   ],
   "source": [
    "# check if the census tracts in the taxi data match the census tracts dataset\n",
    "df_census_tracts.GEOID10.values\n",
    "census_tracts = set([id.as_py() for id in df_census_tracts.GEOID10.values])\n",
    "census_tracts_taxi_pickups = set([int(id) for id in df_cleaned_census_and_location.pickup_census_tract.unique(dropnan=True)])\n",
    "census_tracts_taxi_dropoffs = set([int(id) for id in df_cleaned_census_and_location.dropoff_census_tract.unique(dropnan=True)])\n",
    "\n",
    "print(\"Do the pickup census tract IDs in the taxi trip data match the census tract dataset? \",census_tracts_taxi_pickups.issubset(census_tracts))\n",
    "print(\"Do the dropoff census tract IDs in the taxi trip data match the census tract dataset? \",census_tracts_taxi_dropoffs.issubset(census_tracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns for hourly discretization\n",
    "df_cleaned_census_and_location[\"trip_start_hour\"] = df_cleaned_census_and_location.trip_start_timestamp.dt.hour\n",
    "df_cleaned_census_and_location[\"trip_end_hour\"] = df_cleaned_census_and_location.trip_end_timestamp.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21170643\n"
     ]
    }
   ],
   "source": [
    "print(len(df_cleaned_census_and_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export(hdf5) [----------------------------------------]  0.00% estimated time: unknown                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export(hdf5) [##--------------------------------------]  5.60% estimated time:   216.71s =  3.6m =  0.1h   "
     ]
    }
   ],
   "source": [
    "# export prepared dataframe\n",
    "df_cleaned_census_and_location.export_hdf5('./data/trips_prepared.hdf5', progress=True).export_hdf5('./data/trips_prepared.hdf5', progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
