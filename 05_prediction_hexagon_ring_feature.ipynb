{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import local_helpers as lh\n",
    "import vaex\n",
    "import h3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### Previous demand as input\n",
    "\n",
    "As we have given time series data, it is a common approach to use the demand of previous hours (or days etc.) as an input for the prediction. The assumption we hereby make is that the factors that influence the demand have not changed dramatically within the used time frames. We have decided to construct the following features from previous demand:\n",
    "\n",
    "* 2 hour: The asssumption is that the demand should not change dramatically between three hours.\n",
    "* 24 hours: The asssumption is that the current demand should be comparable to the demand exactly one day ago, as factors such as season, time of the day are the same.\n",
    "* Average demand of the past week at the same day time: This feature is the average of all 7 demand observations of the past week at same time of the day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions loads the dataset either with hexagons or census tract\n",
    "def load_dataset_to_pandas(resolution=10, location_type_hexagon = True):\n",
    "    df = vaex.open('./data/trips_prepared.hdf5')\n",
    "    df.head()\n",
    "\n",
    "    df[\"trip_start_day\"] = df.trip_start_timestamp.dt.day\n",
    "    df[\"trip_start_month\"] = df.trip_start_timestamp.dt.month\n",
    "    df[\"trip_start_hour\"] = df.trip_start_timestamp.dt.hour\n",
    "    df[\"trip_start_minute\"] = df.trip_start_timestamp.dt.minute\n",
    "\n",
    "    if location_type_hexagon:\n",
    "        RESOLUTION = resolution\n",
    "        def geo_to_h3(row1, row2):\n",
    "            return h3.geo_to_h3(row1,row2, RESOLUTION)\n",
    "\n",
    "        # Step 1: For each pickup and drop-off calculate the correct hexagon in the resolution\n",
    "        df['pickup_loc'] = df.apply(geo_to_h3, [df['pickup_centroid_latitude'], df['pickup_centroid_longitude']])\n",
    "    else:\n",
    "        df.rename('pickup_census_tract', 'pickup_loc')\n",
    "\n",
    "    ### Group by hour\n",
    "    df_demand = df.groupby(['trip_start_hour', 'trip_start_month', 'trip_start_day', 'pickup_loc']).agg({'demand': 'count'})\n",
    "        \n",
    "    # Add timestamp as preparation for resampling\n",
    "    df_demand['timestamp'] = pd.to_datetime({'year': 2017, 'month': df_demand['trip_start_month'].to_numpy(), 'day': df_demand['trip_start_day'].to_numpy(), 'hour': df_demand['trip_start_hour'].to_numpy()}).to_numpy()\n",
    "\n",
    "    # convert to pandas df\n",
    "    df_demand = df_demand.to_pandas_df()\n",
    "    \n",
    "    return df_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_hourly(df):\n",
    "    ### Creation of dummy df which contains hourly data dummy data over an entire year per hexagon\n",
    "    # Create a DateTimeIndex with hourly intervals for the year 2017\n",
    "    start_date = '2017-01-01 00:00:00'\n",
    "    end_date = '2017-12-31 23:00:00'\n",
    "    hourly_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "    num_entries_per_year = len(hourly_range)\n",
    "    hour_range = np.tile(hourly_range.hour,len(np.unique(df.pickup_loc)))\n",
    "    month_range = np.tile(hourly_range.month,len(np.unique(df.pickup_loc)))\n",
    "    day_range = np.tile(hourly_range.day,len(np.unique(df.pickup_loc)))\n",
    "    hourly_range = np.tile(hourly_range,len(np.unique(df.pickup_loc)))\n",
    "\n",
    "    # -1 values will indacte that these rows were artificially generated later on\n",
    "    data = {\n",
    "        'trip_start_hour': hour_range,\n",
    "        'trip_start_month': month_range,\n",
    "        'trip_start_day': day_range,\n",
    "        'pickup_loc': np.repeat(np.unique(df.pickup_loc), num_entries_per_year),\n",
    "        'demand': 0,\n",
    "    }\n",
    "\n",
    "    df_hourly = pd.DataFrame(data, index=hourly_range)\n",
    "    df_hourly= df_hourly.set_index([df_hourly.index, 'pickup_loc'])\n",
    "\n",
    "    # introduce multiindex for filling up the df with hourly index later on\n",
    "    df=df.set_index(['timestamp', 'pickup_loc'])\n",
    "\n",
    "    # insert df\n",
    "    df_hourly.update(df)\n",
    "\n",
    "    # clear up multi-index\n",
    "    df_hourly=df_hourly.reset_index()\n",
    "    df_hourly.columns = ['timestamp','pickup_loc','trip_start_hour','trip_start_month','trip_start_day','demand']\n",
    "    return df_hourly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_demand(df):\n",
    "    # insert features 1, 2 and 24 hours previous demand\n",
    "    df['demand_h-1'] = df.sort_values('timestamp').groupby('pickup_loc')['demand'].shift(1)\n",
    "    df['demand_h-2'] = df.sort_values('timestamp').groupby('pickup_loc')['demand'].shift(2)\n",
    "    df['demand_h-24'] = df.sort_values('timestamp').groupby('pickup_loc')['demand'].shift(24)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather features\n",
    "In the descriptive analysis, particularly the analysis of temporal demand patterns, we found that the temperature and demand curves follow similar directions. Therefore, we construct features based on temperature to enable models that capture this relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include weather data\n",
    "First, we have to include the weather data into the dataframe. For this we just need to merge the two datasets, as both are already in hourly frequency. The weather data propose data for minute 53 of an hour. Therefore, we round up to the nearest hour for each row. We suppose that the weather changes in seven minutes can be disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather(df):\n",
    "    # read and merge weather data\n",
    "    df_weather = pd.read_csv('data/weather_data_final.csv')\n",
    "    df_weather['date_time'] = pd.to_datetime(df_weather['date_time'])\n",
    "    df_weather['date_time'] = df_weather['date_time'].dt.ceil('H')\n",
    "    df_weather.rename(columns={'date_time': 'timestamp'}, inplace=True)\n",
    "\n",
    "    # cast data types\n",
    "    df_weather['temp'] = df_weather['temp'].str.replace('\\xa0°F', '').astype(float).fillna(np.nan)\n",
    "    df_weather['dew_point'] = df_weather['dew_point'].str.replace('\\xa0°F', '').astype(float).fillna(np.nan)\n",
    "    df_weather['humidity'] = df_weather['humidity'].str.replace('\\xa0°%', '').astype(float).fillna(np.nan)\n",
    "    df_weather['wind_speed'] = df_weather['wind_speed'].str.replace('\\xa0°mph', '').astype(float).fillna(np.nan)\n",
    "    df_weather['wind_gust'] = df_weather['wind_gust'].str.replace('\\xa0°mph', '').astype(float).fillna(np.nan)\n",
    "    df_weather['pressure'] = df_weather['pressure'].str.replace('\\xa0°in', '').astype(float).fillna(np.nan)\n",
    "    df_weather['precip'] = df_weather['precip'].str.replace('\\xa0°in', '').astype(float).fillna(np.nan)\n",
    "    df = df.merge(df_weather, on='timestamp', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature features\n",
    "In addition to the current temperature, we are add the temperature from 1, 2, and 3 hours prior to the time of taxi demand. We suggest that past temperature conditions could potentially impact the decision to hire a taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_temperature(df):\n",
    "    df['temp_h-1'] = df.sort_values('timestamp').groupby('pickup_loc')['temp'].shift(1)\n",
    "    df['temp_h-2'] = df.sort_values('timestamp').groupby('pickup_loc')['temp'].shift(2)\n",
    "    df['temp_h-3'] = df.sort_values('timestamp').groupby('pickup_loc')['temp'].shift(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation\n",
    "We hypothesize that precipitation has a significant impact on demand. Therefore, we construct features that describe whether it has rained in the last 1-3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_precip(df):\n",
    "    df['precip_h-1'] = df.sort_values('timestamp').groupby('pickup_loc')['precip'].shift(1)\n",
    "    df['precip_h-2'] = df.sort_values('timestamp').groupby('pickup_loc')['precip'].shift(2)\n",
    "    df['precip_h-3'] = df.sort_values('timestamp').groupby('pickup_loc')['precip'].shift(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season\n",
    "We suggest that demand changes over seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long loading time\n",
    "def determine_season(row):\n",
    "    if datetime(2017, 12, 22) <= row.timestamp or row.timestamp < datetime(2017, 3, 20):\n",
    "        return 'winter'\n",
    "    elif datetime(2017, 3, 20) <= row.timestamp < datetime(2017, 6, 21):\n",
    "        return 'spring'\n",
    "    elif datetime(2017, 6, 21) <= row.timestamp < datetime(2017, 9, 23):\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'autumn'\n",
    "\n",
    "def get_season(df):\n",
    "    df['season'] = df.apply((lambda x: determine_season(x)), axis=1)\n",
    "    df = pd.get_dummies(df, columns=['season'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend feature\n",
    "In the descriptive analysis we have seen that demand changes depending on weekend or not. Hence we engineer a feature \"weekend\" which is 1 for all rides on saturday & sunday and zero for all other days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekend(df):\n",
    "    df['weekend'] = df.apply((lambda x: 0 if x.timestamp.weekday() < 5 else 1), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daytime features\n",
    "In addition, descriptive analysis has shown that the time of day, i.e., whether it is night, morning, afternoon, or evening, plays an important role in determining demand. Therefore, we developed four characteristics, each indicating whether a trip occurs during the following times.\n",
    "* Morning: 6 a.m. - 12 p.m.\n",
    "* Afternoon: 12 noon - 6 p.m.\n",
    "* Evening: 6 p.m. - 11 p.m.\n",
    "* Night: 12 a.m. - 6 a.m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daytime(df):\n",
    "    df['daytime'] = df[\"timestamp\"].apply(lambda x: lh.get_pnt_day_with_pnt_week(x))\n",
    "    df = pd.get_dummies(df, columns=['daytime'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Features\n",
    "Events such as public holidays might influence the demand. In order to capture these patterns we introduce the public holiday feature\n",
    "\n",
    "There were several public holidays in Boston:\n",
    "* Martin Luther King Day: Monday, January 16, 2017\n",
    "* Lincoln's Birthday: Monday, February 13, 2017\n",
    "* Washington's Birthday (President's Day): Monday, February 20, 2017\n",
    "* Memorial Day: Monday, May 29, 2017\n",
    "* Independence Day: Tuesday, July 04, 2017\n",
    "* Labor Day: Monday, September 04, 2017\n",
    "* Columbus Day: Monday, October 09, 2017\n",
    "* Veterans' Day: Friday, November 10, 2017\n",
    "* Thanksgiving Day: Thursday, November 23, 2017\n",
    "* Thanksgiving Day: Friday, November 24, 2017\n",
    "* Christmas Day: Monday, December 25, 2017\n",
    "\n",
    "These events might have influenced the demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_dates = [\n",
    "    datetime(2017, 1, 2),   # New Year's Day\n",
    "    datetime(2017, 1, 16),  # Martin Luther King Day\n",
    "    datetime(2017, 2, 13),  # Lincoln's Birthday\n",
    "    datetime(2017, 2, 20),  # Washington's Birthday (President's Day)\n",
    "    datetime(2017, 5, 29),  # Memorial Day\n",
    "    datetime(2017, 7, 4),   # Independence Day\n",
    "    datetime(2017, 9, 4),   # Labor Day\n",
    "    datetime(2017, 10, 9),  # Columbus Day\n",
    "    datetime(2017, 11, 10), # Veterans' Day\n",
    "    datetime(2017, 11, 23), # Thanksgiving Day\n",
    "    datetime(2017, 11, 24), # Day after Thanksgiving\n",
    "    datetime(2017, 12, 25), # Christmas Day\n",
    "]\n",
    "\n",
    "def get_holiday_dates(df):\n",
    "    df['public_holiday'] = df.apply((lambda x: 1 if x.timestamp in holiday_dates else 0), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand of surrounding hexagons feature\n",
    "We expect a high correlation between the demand of one hexagon and the demand in the surrounding hexagons. With this feature we can observe demand patterns in a greater radius than only in the observed location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_tract_neighbors(census_tract_id):\n",
    "    df_census_tracts = pd.read_csv(\"data/chicago_census_tracts.csv\")\n",
    "    df_census_tracts['the_geom'] = df_census_tracts['the_geom'].apply(wkt.loads)\n",
    "    df_census_tracts = df_census_tracts.rename(columns={'the_geom': 'geometry'})\n",
    "    df_census_tracts.head()\n",
    "    df_census_tracts = df_census_tracts[[\"geometry\", \"GEOID10\"]]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df_census_tracts, geometry='geometry')\n",
    "    gdf = gdf.set_crs(epsg=4326, allow_override=True)\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    buffer_distance = 1000  # distance in meters (1 km here)\n",
    "    gdf_buffered = gdf.copy()\n",
    "    gdf_buffered['geometry'] = gdf.buffer(buffer_distance)\n",
    "    gdf['geometry'] = gdf_buffered.geometry  # Replace original geometry with buffered one\n",
    "    census_tract_neighbors = gpd.sjoin(gdf, gdf, how='left', predicate='intersects')\n",
    "    # Remove self-matches (where polygons intersect with themselves)\n",
    "    census_tract_neighbors = census_tract_neighbors[census_tract_neighbors.index != census_tract_neighbors.index_right]\n",
    "    census_tract_neighbors_grouped = census_tract_neighbors.groupby('GEOID10_left')['GEOID10_right'].apply(list)\n",
    "    return census_tract_neighbors_grouped[census_tract_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pickup_loc</th>\n",
       "      <th>trip_start_hour</th>\n",
       "      <th>trip_start_month</th>\n",
       "      <th>trip_start_day</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    pickup_loc  trip_start_hour  trip_start_month  \\\n",
       "0 2017-01-01 00:00:00  1.703101e+10                0                 1   \n",
       "1 2017-01-01 01:00:00  1.703101e+10                1                 1   \n",
       "2 2017-01-01 02:00:00  1.703101e+10                2                 1   \n",
       "3 2017-01-01 03:00:00  1.703101e+10                3                 1   \n",
       "4 2017-01-01 04:00:00  1.703101e+10                4                 1   \n",
       "\n",
       "   trip_start_day  demand  \n",
       "0               1       0  \n",
       "1               1       0  \n",
       "2               1       0  \n",
       "3               1       0  \n",
       "4               1       0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census= load_dataset_to_pandas(resolution=5, location_type_hexagon=False)\n",
    "df_census = resample_to_hourly(df_census)\n",
    "df_comm_areas = pd.read_csv(\"data/chicago_census_tracts.csv\")\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h3' has no attribute 'is_valid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m         neighbor_demand \u001b[38;5;241m=\u001b[39m df_timestamp[df_timestamp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(neighbors)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand_h-1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m neighbor_demand\n\u001b[0;32m---> 12\u001b[0m df_census[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbor_demand_h-1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_census\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_neighbor_demand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_census\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_census\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickup_loc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aaa_dev/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/aaa_dev/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aaa_dev/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/aaa_dev/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[51], line 12\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      8\u001b[0m         neighbor_demand \u001b[38;5;241m=\u001b[39m df_timestamp[df_timestamp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(neighbors)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand_h-1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m neighbor_demand\n\u001b[0;32m---> 12\u001b[0m df_census[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbor_demand_h-1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_census\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mget_neighbor_demand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_census\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_census\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickup_loc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m, in \u001b[0;36mget_neighbor_demand\u001b[0;34m(df_timestamp, pickup_loc)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_neighbor_demand\u001b[39m(df_timestamp, pickup_loc):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mh3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_valid\u001b[49m(pickup_loc):\n\u001b[1;32m      4\u001b[0m         neighbors \u001b[38;5;241m=\u001b[39m h3\u001b[38;5;241m.\u001b[39mk_ring(pickup_loc, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m         neighbor_demand \u001b[38;5;241m=\u001b[39m df_timestamp[df_timestamp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(neighbors)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemand_h-1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'h3' has no attribute 'is_valid'"
     ]
    }
   ],
   "source": [
    "def get_neighbor_demand(df_timestamp, pickup_loc):\n",
    "    \n",
    "    if h3.is_valid(pickup_loc):\n",
    "        neighbors = h3.k_ring(pickup_loc, k=1)\n",
    "        neighbor_demand = df_timestamp[df_timestamp['pickup_loc'].isin(neighbors)]['demand_h-1'].mean()\n",
    "    else:\n",
    "        neighbors = get_census_tract_neighbors(pickup_loc)\n",
    "        neighbor_demand = df_timestamp[df_timestamp['pickup_loc'].isin(neighbors)]['demand_h-1'].mean()\n",
    "        \n",
    "    return neighbor_demand\n",
    "\n",
    "df_census['neighbor_demand_h-1'] = df_census.apply(lambda row: get_neighbor_demand(df_census[df_census['timestamp'] == row['timestamp']], row['pickup_loc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prepared_data(location_type_hexagon=True, resolution=10):\n",
    "    df = load_dataset_to_pandas(location_type_hexagon=location_type_hexagon, resolution=resolution)\n",
    "    df = resample_to_hourly(df)\n",
    "    df = get_past_demand(df)\n",
    "    df = merge_weather(df)\n",
    "    df = get_past_temperature(df)\n",
    "    df = get_past_precip(df)\n",
    "    df = get_season(df)\n",
    "    df = get_weekend(df)\n",
    "    df = get_daytime(df)\n",
    "    df = get_holiday_dates(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pickup_loc</th>\n",
       "      <th>trip_start_hour</th>\n",
       "      <th>trip_start_month</th>\n",
       "      <th>trip_start_day</th>\n",
       "      <th>demand</th>\n",
       "      <th>demand_h-1</th>\n",
       "      <th>demand_h-2</th>\n",
       "      <th>demand_h-24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127315</th>\n",
       "      <td>2017-12-31 19:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127316</th>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127317</th>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127318</th>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127319</th>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3127320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp    pickup_loc  trip_start_hour  trip_start_month  \\\n",
       "0       2017-01-01 00:00:00  1.703101e+10                0                 1   \n",
       "1       2017-01-01 01:00:00  1.703101e+10                1                 1   \n",
       "2       2017-01-01 02:00:00  1.703101e+10                2                 1   \n",
       "3       2017-01-01 03:00:00  1.703101e+10                3                 1   \n",
       "4       2017-01-01 04:00:00  1.703101e+10                4                 1   \n",
       "...                     ...           ...              ...               ...   \n",
       "3127315 2017-12-31 19:00:00  1.703198e+10               19                12   \n",
       "3127316 2017-12-31 20:00:00  1.703198e+10               20                12   \n",
       "3127317 2017-12-31 21:00:00  1.703198e+10               21                12   \n",
       "3127318 2017-12-31 22:00:00  1.703198e+10               22                12   \n",
       "3127319 2017-12-31 23:00:00  1.703198e+10               23                12   \n",
       "\n",
       "         trip_start_day  demand  demand_h-1  demand_h-2  demand_h-24  \n",
       "0                     1       0         NaN         NaN          NaN  \n",
       "1                     1       0         0.0         NaN          NaN  \n",
       "2                     1       0         0.0         0.0          NaN  \n",
       "3                     1       0         0.0         0.0          NaN  \n",
       "4                     1       0         0.0         0.0          NaN  \n",
       "...                 ...     ...         ...         ...          ...  \n",
       "3127315              31       4        15.0        14.0         17.0  \n",
       "3127316              31       9         4.0        15.0         16.0  \n",
       "3127317              31      10         9.0         4.0         20.0  \n",
       "3127318              31      13        10.0         9.0         11.0  \n",
       "3127319              31       2        13.0        10.0         20.0  \n",
       "\n",
       "[3127320 rows x 9 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pickup_loc</th>\n",
       "      <th>trip_start_hour</th>\n",
       "      <th>trip_start_month</th>\n",
       "      <th>trip_start_day</th>\n",
       "      <th>demand</th>\n",
       "      <th>demand_h-1</th>\n",
       "      <th>demand_h-2</th>\n",
       "      <th>demand_h-24</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>weekend</th>\n",
       "      <th>daytime_afternoon_week</th>\n",
       "      <th>daytime_afternoon_weekend</th>\n",
       "      <th>daytime_evening_week</th>\n",
       "      <th>daytime_evening_weekend</th>\n",
       "      <th>daytime_morning_week</th>\n",
       "      <th>daytime_morning_weekend</th>\n",
       "      <th>daytime_night_week</th>\n",
       "      <th>daytime_night_weekend</th>\n",
       "      <th>public_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>1.703101e+10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127315</th>\n",
       "      <td>2017-12-31 19:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127316</th>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127317</th>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127318</th>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127319</th>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>1.703198e+10</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3127320 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp    pickup_loc  trip_start_hour  trip_start_month  \\\n",
       "0       2017-01-01 00:00:00  1.703101e+10                0                 1   \n",
       "1       2017-01-01 01:00:00  1.703101e+10                1                 1   \n",
       "2       2017-01-01 02:00:00  1.703101e+10                2                 1   \n",
       "3       2017-01-01 03:00:00  1.703101e+10                3                 1   \n",
       "4       2017-01-01 04:00:00  1.703101e+10                4                 1   \n",
       "...                     ...           ...              ...               ...   \n",
       "3127315 2017-12-31 19:00:00  1.703198e+10               19                12   \n",
       "3127316 2017-12-31 20:00:00  1.703198e+10               20                12   \n",
       "3127317 2017-12-31 21:00:00  1.703198e+10               21                12   \n",
       "3127318 2017-12-31 22:00:00  1.703198e+10               22                12   \n",
       "3127319 2017-12-31 23:00:00  1.703198e+10               23                12   \n",
       "\n",
       "         trip_start_day  demand  demand_h-1  demand_h-2  demand_h-24  \\\n",
       "0                     1       0         NaN         NaN          NaN   \n",
       "1                     1       0         0.0         NaN          NaN   \n",
       "2                     1       0         0.0         0.0          NaN   \n",
       "3                     1       0         0.0         0.0          NaN   \n",
       "4                     1       0         0.0         0.0          NaN   \n",
       "...                 ...     ...         ...         ...          ...   \n",
       "3127315              31       4        15.0        14.0         17.0   \n",
       "3127316              31       9         4.0        15.0         16.0   \n",
       "3127317              31      10         9.0         4.0         20.0   \n",
       "3127318              31      13        10.0         9.0         11.0   \n",
       "3127319              31       2        13.0        10.0         20.0   \n",
       "\n",
       "               date  ... weekend  daytime_afternoon_week  \\\n",
       "0               NaN  ...       1                   False   \n",
       "1        2017-01-01  ...       1                   False   \n",
       "2        2017-01-01  ...       1                   False   \n",
       "3        2017-01-01  ...       1                   False   \n",
       "4        2017-01-01  ...       1                   False   \n",
       "...             ...  ...     ...                     ...   \n",
       "3127315  2017-12-31  ...       1                   False   \n",
       "3127316  2017-12-31  ...       1                   False   \n",
       "3127317  2017-12-31  ...       1                   False   \n",
       "3127318  2017-12-31  ...       1                   False   \n",
       "3127319  2017-12-31  ...       1                   False   \n",
       "\n",
       "         daytime_afternoon_weekend  daytime_evening_week  \\\n",
       "0                            False                 False   \n",
       "1                            False                 False   \n",
       "2                            False                 False   \n",
       "3                            False                 False   \n",
       "4                            False                 False   \n",
       "...                            ...                   ...   \n",
       "3127315                      False                 False   \n",
       "3127316                      False                 False   \n",
       "3127317                      False                 False   \n",
       "3127318                      False                 False   \n",
       "3127319                      False                 False   \n",
       "\n",
       "         daytime_evening_weekend  daytime_morning_week  \\\n",
       "0                          False                 False   \n",
       "1                          False                 False   \n",
       "2                          False                 False   \n",
       "3                          False                 False   \n",
       "4                          False                 False   \n",
       "...                          ...                   ...   \n",
       "3127315                     True                 False   \n",
       "3127316                     True                 False   \n",
       "3127317                     True                 False   \n",
       "3127318                     True                 False   \n",
       "3127319                    False                 False   \n",
       "\n",
       "         daytime_morning_weekend  daytime_night_week daytime_night_weekend  \\\n",
       "0                          False               False                  True   \n",
       "1                          False               False                  True   \n",
       "2                          False               False                  True   \n",
       "3                          False               False                  True   \n",
       "4                          False               False                  True   \n",
       "...                          ...                 ...                   ...   \n",
       "3127315                    False               False                 False   \n",
       "3127316                    False               False                 False   \n",
       "3127317                    False               False                 False   \n",
       "3127318                    False               False                 False   \n",
       "3127319                    False               False                  True   \n",
       "\n",
       "         public_holiday  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "3127315               0  \n",
       "3127316               0  \n",
       "3127317               0  \n",
       "3127318               0  \n",
       "3127319               0  \n",
       "\n",
       "[3127320 rows x 39 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census = get_prepared_data(False)\n",
    "df_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n",
    "We have different measurement scales:\n",
    "\n",
    "Ordinal (natural order, but no quantifiable difference between values or binary):\n",
    "- season_x \n",
    "- daytime_x\n",
    "- hour_of_day\n",
    "Metric (equidistant scale):\n",
    "- temp\n",
    "- demand\n",
    "- precipitation\n",
    "Nominal:\n",
    "- public_holiday\n",
    "- weekend\n",
    "\n",
    "We do 2 different analysis:\n",
    "- Metric <-> Metric (Pearson)\n",
    "- Ordinal & Nominal <-> Metric, Ordinal & Nominal <-> Ordinal & Nominal (Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_demand_hourly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 6 Min loading time\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# engineer features\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_demand \u001b[38;5;241m=\u001b[39m merge_weather(\u001b[43mdf_demand_hourly\u001b[49m)\n\u001b[1;32m      4\u001b[0m df_demand \u001b[38;5;241m=\u001b[39m get_past_temperature(df_demand)\n\u001b[1;32m      5\u001b[0m df_demand \u001b[38;5;241m=\u001b[39m get_past_precip(df_demand)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_demand_hourly' is not defined"
     ]
    }
   ],
   "source": [
    "# 6 Min loading time\n",
    "# engineer features\n",
    "df_demand = merge_weather(df_demand_hourly)\n",
    "df_demand = get_past_temperature(df_demand)\n",
    "df_demand = get_past_precip(df_demand)\n",
    "df_demand = get_season(df_demand)\n",
    "df_demand = get_weekend(df_demand)\n",
    "df_demand = get_daytime(df_demand)\n",
    "df_demand = get_holiday_dates(df_demand)\n",
    "df_demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = df_demand[[\"demand\", \"temp\", \"temp_h-1\", \"temp_h-2\", \"temp_h-3\", \"demand_h-1\", \"demand_h-2\", \"demand_h-24\"]]\n",
    "sns.heatmap(metric.corr(method=\"pearson\"), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_and_nominal = df_demand[\n",
    "        [\"season_autumn\", \"season_spring\", \"season_summer\", \"season_winter\", \"daytime_morning_week\",\n",
    "        \"daytime_afternoon_week\", \"daytime_evening_week\", \"daytime_night_week\", \"daytime_morning_weekend\",\n",
    "        \"daytime_afternoon_weekend\", \"daytime_evening_weekend\", \"daytime_night_weekend\", \"public_holiday\",\n",
    "        \"weekend\"]] #\"hour\"\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(pd.concat([ordinal_and_nominal, metric], axis=1).corr(method=\"spearman\"), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def train_validation_test_split(X, y, train_ratio=0.6, validation_ratio=0.2, test_ratio=0.2, random_state=None):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=random_state)\n",
    "\n",
    "    # Calculate the remaining ratio after train-test split\n",
    "    remaining_ratio = 1.0 - test_ratio\n",
    "\n",
    "    # Calculate the proportional validation ratio based on the remaining ratio\n",
    "    validation_ratio_prop = validation_ratio / remaining_ratio\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        X_train, y_train, test_size=validation_ratio_prop, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (aaadev)",
   "language": "python",
   "name": "aaa_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
