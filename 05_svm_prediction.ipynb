{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7b1c2d-baf2-4963-97f7-401930a12cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2b9921-e9a1-4982-8575-10e91dfd0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNELS = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# resolution 0 is census tracts\n",
    "RESOLUTIONS = [0, 3, 4, 5, 6, 7, 8, 9]\n",
    "TARGETS = ['demand_target_bucket_1', 'demand_target_bucket_2', 'demand_target_bucket_6', 'demand_target_bucket_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858b7f49-ec1c-48c6-8bf0-1c198927264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['trip_start_hour', 'trip_start_month',\n",
    "       'trip_start_day', 'temp', 'humidity', 'wind_speed',\n",
    "       'wind_gust', 'pressure', 'precip', 'Clear/Sunny',\n",
    "       'Cloudy', 'Other', 'Rain/Storms',\n",
    "       'Snow/Winter Conditions', 'temp_h-1', 'precip_h-1', 'autumn',\n",
    "       'spring', 'summer', 'winter', 'weekend',\n",
    "       'afternoon_week', 'afternoon_weekend', 'evening_week',\n",
    "       'evening_weekend', 'morning_week', 'morning_weekend', 'night_week',\n",
    "       'night_weekend', 'is_holiday', 'demand_h-1', 'demand_h-2',\n",
    "       'demand_h-24', 'demand_p-24', 'demand_bucket_2', 'demand_bucket_6',\n",
    "       'demand_bucket_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abbf645-f949-495d-98f6-a2fd5ae05a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(df, prediction_horizon):\n",
    "    y = df[f'demand_target_bucket_{prediction_horizon}']\n",
    "    X = df[FEATURES +[f'pickup_demand_target_bucket_{prediction_horizon}']]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee077198-338c-4543-92f9-492e280ca065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test=None):\n",
    "    # Create the scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler using the training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform both the training and test data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    if X_test is not None: # Explicitly check against None\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        return X_train_scaled, X_test_scaled\n",
    "    return X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13eb35fa-8f4e-4ced-b7d5-1c02e3436618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_by_resolution(resolution, census=False):\n",
    "    if census:\n",
    "        df_train = pd.read_csv('./data/model_input/0_res_train.csv')\n",
    "        df_test = pd.read_csv('./data/model_input/0_res_test.csv')\n",
    "        return df_train, df_test\n",
    "    \n",
    "    df_train = pd.read_csv(f'./data/model_input/{resolution}_res_train.csv')\n",
    "    df_test = pd.read_csv(f'./data/model_input/{resolution}_res_test.csv')\n",
    "    return df_train, df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1368b8-1d7b-45db-b5c8-34c77510abe4",
   "metadata": {},
   "source": [
    "## Identify best Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d2940-d0f5-41c3-95b6-d926fb30c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   6.7s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   6.4s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   6.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   6.6s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   6.8s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   7.2s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   7.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   7.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   7.2s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   7.2s\n",
      "[CV] END ................................C=10, kernel=linear; total time=  10.1s\n",
      "[CV] END ................................C=10, kernel=linear; total time=  10.4s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   9.6s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   9.3s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   9.4s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   7.6s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   7.6s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = get_df_by_resolution(3)\n",
    "X_train, y_train = get_X_y(df_train, 1)\n",
    "X_train_scaled = scale_data(X_train)\n",
    "\n",
    "# Define hyperparameter grid for each kernel\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': [0.1, 1, 10]},\n",
    "    {'kernel': ['poly'], 'C': [0.1, 1, 10], 'degree': [2, 3], 'gamma': ['scale']},\n",
    "    {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': ['auto', 'scale']},\n",
    "    {'kernel': ['sigmoid'], 'C': [0.1, 1, 10], 'gamma': ['auto']}\n",
    "]\n",
    "\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(SVR(epsilon=0.1), param_grid, cv=5, verbose=2, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8591fe-8a14-43ad-8880-772c3d2ebece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the results\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Create empty lists to hold the results for each kernel\n",
    "scores = []\n",
    "KERNELS = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# Iterate over the kernels to find the best score for each\n",
    "for kernel in KERNELS:\n",
    "    kernel_mask = [param['kernel'] == kernel for param in cv_results['params']]\n",
    "    kernel_scores = cv_results['mean_test_score'][kernel_mask]\n",
    "    best_kernel_score = max(kernel_scores)\n",
    "    scores.append(best_kernel_score)\n",
    "\n",
    "# Plot the results\n",
    "plt.bar(KERNELS, [abs(score) for score in scores])\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.xlabel('Kernel')\n",
    "plt.title('Performance of Best Setup for Each Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bad5d3-75da-43b7-ba5f-85e1cef438fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTIONS = [0, 3, 4, 5, 6, 7, 8, 9]\n",
    "TARGET_HORIOZONS = [1, 2, 6, 24]\n",
    "\n",
    "for resolution in RESOLUTIONS:\n",
    "    for horizon in TARGET_HORIOZONS:   \n",
    "        # get data\n",
    "        df_train, df_test = get_df_by_resolution(resolution)\n",
    "        X_train, y_train = get_X_y(df_train, TARGET_HORIOZONS)\n",
    "        X_train, y_train = get_X_y(df_test, TARGET_HORIOZONS)\n",
    "        X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef057d-e009-4d7d-9a49-629fa3034b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTIONS = [0, 3, 4, 5, 6, 7, 8, 9]\n",
    "TARGET_HORIOZONS = [1, 2, 6, 24]\n",
    "\n",
    "RESOLUTIONS = [0, 3]\n",
    "TARGET_HORIOZONS = [1, 2]\n",
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Resolution', 'Target Horizon', 'RMSE'])\n",
    "\n",
    "for resolution in RESOLUTIONS:\n",
    "    rmse_per_horizon = []\n",
    "    for horizon in TARGET_HORIOZONS:\n",
    "        print(f'RESOLUTION:{resolution} - HORIZON: {horizon}')\n",
    "        # Get and preprocess data\n",
    "        df_train, df_test = get_df_by_resolution(resolution)\n",
    "        X_train, y_train = get_X_y(df_train, horizon)\n",
    "        X_test, y_test = get_X_y(df_test, horizon)\n",
    "        X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "\n",
    "        # Define and train SVR\n",
    "        param_grid = [\n",
    "            {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale']}\n",
    "        ]\n",
    "        grid_search = GridSearchCV(SVR(), param_grid, scoring='neg_root_mean_squared_error', cv=5)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        y_pred = grid_search.predict(X_test_scaled)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # Store results\n",
    "        results_df = results_df.append({'Resolution': resolution, 'Target Horizon': horizon, 'RMSE': rmse}, ignore_index=True)\n",
    "        rmse_per_horizon.append(rmse)\n",
    "\n",
    "    # Plot results for current resolution\n",
    "    plt.plot(TARGET_HORIOZONS, rmse_per_horizon, label=f'Resolution {resolution}')\n",
    "    plt.xlabel('Target Horizon')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('RMSE vs Target Horizon')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (aaadev)",
   "language": "python",
   "name": "aaa_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
