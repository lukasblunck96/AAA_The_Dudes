{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoI\n",
    "\n",
    "Script creates for different spacial resolutions 4 count-values for different categories of point of interests using the overpass open-street-map api.\n",
    "\n",
    "Those categories contain the following places:\n",
    "\n",
    "Catering:\n",
    "- cafe\n",
    "- fast_food\n",
    "- food_court\n",
    "- restaurant\n",
    "- supermarket\n",
    "\n",
    "Transportation:\n",
    "- bicycle_parking\n",
    "- bus_station\n",
    "- taxi\n",
    "- railway_stations\n",
    "- airports\n",
    "\n",
    "Hans Entertainment:\n",
    "- arts_centre\n",
    "- brothel\n",
    "- cinema\n",
    "- conference_centre\n",
    "- events_venue\n",
    "- music_venue\n",
    "- nightclub\n",
    "- stripclub\n",
    "- swingerclub\n",
    "- theatre\n",
    "- bar\n",
    "- pub\n",
    "\n",
    "Healthcare:\n",
    "- clinic\n",
    "- dentist\n",
    "- doctors\n",
    "- hospital\n",
    "- pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from shapely.geometry import Polygon\n",
    "import h3\n",
    "import pandas as pd\n",
    "import vaex\n",
    "import shapely\n",
    "from shapely.ops import unary_union\n",
    "import shapely.wkt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes with Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = vaex.open('./data/trips_prepared.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overpass_mode = False\n",
    "\n",
    "df_hexagons_res_2 = create_hexagon_polygon_df(2, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_3 = create_hexagon_polygon_df(3, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_4 = create_hexagon_polygon_df(4, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_5 = create_hexagon_polygon_df(5, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_6 = create_hexagon_polygon_df(6, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_7 = create_hexagon_polygon_df(7, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_8 = create_hexagon_polygon_df(8, df_cleaned, overpass_mode)\n",
    "df_hexagons_res_9 = create_hexagon_polygon_df(9, df_cleaned, overpass_mode)\n",
    "df_census_tracts = create_census_tracts_df(overpass_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the city center and central business district for feature engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/high_demand_places.json')\n",
    "high_demand_places = json.load(f)\n",
    "\n",
    "\n",
    "multi_poly = shapely.wkt.loads(high_demand_places['airport_multipolygon'])\n",
    "airport_polygon = unary_union(multi_poly)\n",
    "\n",
    "multi_poly = shapely.wkt.loads(high_demand_places['business_district_multipolygon'])\n",
    "business_district_polygon = unary_union(multi_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[df_hexagons_res_2, 'hexagons_res_2'], [df_hexagons_res_3, 'hexagons_res_3'], [df_hexagons_res_4, 'hexagons_res_4'], [df_hexagons_res_5, 'hexagons_res_5'], [df_hexagons_res_6, 'hexagons_res_6'], [df_hexagons_res_7, 'hexagons_res_7'], [df_hexagons_res_8, 'hexagons_res_8'], [df_hexagons_res_9, 'hexagons_res_9'], [df_census_tracts, 'census_tracts']]\n",
    "\n",
    "folder =  'airport_locations_v2'\n",
    "#'business_district_location_v2'\n",
    "\n",
    "for d in data:\n",
    "    result = pd.DataFrame(columns=['id'])\n",
    "\n",
    "    for index, row in d[0].iterrows():\n",
    "\n",
    "        if row['geometry'].intersects(airport_polygon):\n",
    "            result.loc[len(result)] = [row['id']]\n",
    "            \n",
    "        \n",
    "    result.to_csv(f'./data/{folder}/{d[1]}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "type",
     "evalue": "Cannot save file into a non-existent directory: 'data/poi_output_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[39m=\u001b[39m [[df_hexagons_res_2, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_2\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_3, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_3\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_4, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_4\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_5, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_5\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_6, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_6\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_7, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_7\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_8, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_8\u001b[39m\u001b[39m'\u001b[39m], [df_hexagons_res_9, \u001b[39m'\u001b[39m\u001b[39mhexagons_res_9\u001b[39m\u001b[39m'\u001b[39m], [df_census_tracts, \u001b[39m'\u001b[39m\u001b[39mcensus_tracts\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data:\n\u001b[0;32m----> 5\u001b[0m     create_output_csv(d[\u001b[39m0\u001b[39;49m], d[\u001b[39m1\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mcreate_output_csv\u001b[0;34m(df, file)\u001b[0m\n\u001b[1;32m      9\u001b[0m     healthcare \u001b[39m=\u001b[39m call_overpass_api(create_api_body_healthcare(row[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     11\u001b[0m     result\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(result)] \u001b[39m=\u001b[39m [row[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m], catering, transportation, entertainment, healthcare]\n\u001b[0;32m---> 15\u001b[0m result\u001b[39m.\u001b[39;49mto_csv(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/poi_output_v2/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AAA_The_Dudes/lib/python3.10/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/AAA_The_Dudes/lib/python3.10/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/envs/AAA_The_Dudes/lib/python3.10/site-packages/pandas/io/formats/csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/envs/AAA_The_Dudes/lib/python3.10/site-packages/pandas/io/common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 737\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    741\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AAA_The_Dudes/lib/python3.10/site-packages/pandas/io/common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data/poi_output_v2'"
     ]
    }
   ],
   "source": [
    "data = [[df_hexagons_res_2, 'hexagons_res_2'], [df_hexagons_res_3, 'hexagons_res_3'], [df_hexagons_res_4, 'hexagons_res_4'], [df_hexagons_res_5, 'hexagons_res_5'], [df_hexagons_res_6, 'hexagons_res_6'], [df_hexagons_res_7, 'hexagons_res_7'], [df_hexagons_res_8, 'hexagons_res_8'], [df_hexagons_res_9, 'hexagons_res_9'], [df_census_tracts, 'census_tracts']]\n",
    "\n",
    "\n",
    "for d in data:\n",
    "    create_output_csv(d[0], d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_csv(df, file):\n",
    "    result = pd.DataFrame(columns=['id', 'catering', 'transportation', 'entertainment', 'healthcare'])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        catering = call_overpass_api(create_api_body_catering(row['geometry']))\n",
    "        transportation = call_overpass_api(create_api_body_transportation(row['geometry']))\n",
    "        entertainment = call_overpass_api(create_api_body_entertainment(row['geometry']))\n",
    "        healthcare = call_overpass_api(create_api_body_healthcare(row['geometry']))\n",
    "\n",
    "        result.loc[len(result)] = [row['id'], catering, transportation, entertainment, healthcare]\n",
    "\n",
    "\n",
    "\n",
    "    result.to_csv(f'./data/poi_output_v2/{file}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_overpass_api(body):\n",
    "    response = requests.post('http://overpass-api.de/api/interpreter', data={'data': body})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result['elements'][0]['tags']['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_census_tracts_df(overpass: True):\n",
    "    df_census_tracts = pd.read_csv(\"./data/chicago_census_tracts.csv\")\n",
    "    poly_df = pd.DataFrame(columns=['id', 'geometry'])\n",
    "\n",
    "    for index, row in df_census_tracts.iterrows():\n",
    "        polygon = row['the_geom']\n",
    "        multi_poly = shapely.wkt.loads(polygon)\n",
    "        poly = unary_union(multi_poly)\n",
    "\n",
    "        if overpass:\n",
    "            poly_df.loc[len(poly_df)] = [row['NAMELSAD10'], polygon_to_overpass(poly)]\n",
    "        else:\n",
    "            poly_df.loc[len(poly_df)] = [row['GEOID10'], poly]\n",
    "\n",
    "    return poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_hexagon_polygon_df(res, trip_df, overpass: True):\n",
    "\n",
    "    global resolution\n",
    "    resolution = res\n",
    "\n",
    "    tmp_df = trip_df.copy()\n",
    "    poly_df = pd.DataFrame(columns=['id', 'geometry'])\n",
    "    \n",
    "    tmp_df['hex'] = tmp_df.apply(geo_to_h3, [tmp_df['pickup_centroid_latitude'], tmp_df['pickup_centroid_longitude']])\n",
    "    \n",
    "    unique_pickup_values = tmp_df['hex'].unique()\n",
    "\n",
    "    for nh in unique_pickup_values:\n",
    "        if overpass:\n",
    "            poly_df.loc[len(poly_df)] = [nh, polygon_to_overpass(hex_geo_id_to_polygon(nh))]\n",
    "        else:\n",
    "            poly_df.loc[len(poly_df)] = [nh, hex_geo_id_to_polygon(nh)]\n",
    "\n",
    "    return poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_to_h3(col1, col2):\n",
    "    return h3.geo_to_h3(col1, col2, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_geo_id_to_polygon(hex_id):\n",
    "    return Polygon(h3.h3_to_geo_boundary(h=hex_id, geo_json=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_to_overpass(poly):\n",
    "    exterior_coords = poly.exterior.coords\n",
    "    \n",
    "    coords_str = ' '.join(f'{lon} {lat}' for lat, lon in exterior_coords)\n",
    "    \n",
    "    return f'poly:\"{coords_str}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_api_body_catering(poly_string):\n",
    "    return f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "        node[shop=supermarket]({poly_string});\n",
    "        node[amenity=cafe]({poly_string});\n",
    "        node[amenity=fast_food]({poly_string});\n",
    "        node[amenity=restaurant]({poly_string});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_api_body_transportation(poly_string):\n",
    "    return f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "        node[railway=station]({poly_string});\n",
    "        node[aeroway]({poly_string});\n",
    "        node[amenity=bicycle_parking]({poly_string});\n",
    "        node[amenity=bus_station]({poly_string});\n",
    "        node[amenity=taxi]({poly_string});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_api_body_entertainment(poly_string):\n",
    "    return f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "        node[amenity=arts_centre]({poly_string});\n",
    "        node[amenity=brothel]({poly_string});\n",
    "        node[amenity=cinema]({poly_string});\n",
    "        node[amenity=conference_centre]({poly_string});\n",
    "        node[amenity=events_venue]({poly_string});\n",
    "        node[amenity=music_venue]({poly_string});\n",
    "        node[amenity=nightclub]({poly_string});\n",
    "        node[amenity=stripclub]({poly_string});\n",
    "        node[amenity=swingerclub]({poly_string});\n",
    "        node[amenity=theatre]({poly_string});\n",
    "        node[amenity=bar]({poly_string});\n",
    "        node[amenity=pub]({poly_string});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_api_body_healthcare(poly_string):\n",
    "    return f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "        node[amenity=clinic]({poly_string});\n",
    "        node[amenity=dentist]({poly_string});\n",
    "        node[amenity=doctors]({poly_string});\n",
    "        node[amenity=hospital]({poly_string});\n",
    "        node[amenity=pharmacy]({poly_string});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
